---
title: 01-什么是网络爬虫
date: 2022-11-19 16:53:48
author: AI悦创
isOriginal: true
category: Python 网络爬虫专栏
tag:
    - Crawler
icon: debug
sticky: false
star: false
article: true
timeline: true
image: false
navbar: true
sidebarIcon: true
headerDepth: 5
comment: true
lastUpdated: true
editLink: false
backToTop: true
toc: true
---

互联网诞生之初，是为了让人们更容易的分享数据、交流通讯。互联网是桥梁，连接了世界各地的人们。网站的点击、浏览都是人为的，与你聊天的也是活生生的人。然而，随着技术的发展，人们对数据的渴望，出现了各种网络机器人，这个时候，你不知道屏幕那端跟你聊天的是一个人还是一条狗，你也不知道你网站的浏览量是人点击出来的，还是机器爬出来的。

表面上看，互联网上是各种各样的人；暗地里，已经布满了形形色色的网络爬虫。

## 一、搜索引擎时代的网络爬虫

关于网络爬虫的概念，我们先来瞅瞅维基百科（Wikipedia）上面的定义：

> 网络爬虫（英语：web crawler），也叫网上蜘蛛（spider），是一种用来自动浏览万维网的网络机器人。其目的一般为编纂网络索引。

这里提到的编纂网络索引，就是搜索引擎干的事情。我们对搜索引擎并不陌生，Google、百度等搜索引擎可能每天都在帮我们快速获得信息。可能小猿们要问，搜索引擎的工作过程是怎样的呢？

首先，就是有网络爬虫不断抓取各个网站的网页，存放到搜索引擎的数据库；
接着，索引程序读取数据库的网页进行清理，建立倒排索引；
最后，搜索程序接收用户的查询关键词，去索引里面找到相关内容，并通过一定的排序算法（Pagerank等）把最相关最好的结果排在最前面呈现给用户。

看上去简简单单的三个部分，却构成了强大复杂的搜索引擎系统。而网络爬虫是其中最基础也很重要的一部分，它决定着搜索引擎数据的完整性和丰富性。我们也看到网络爬虫的主要作用是获取数据。

由此简单地说，网络爬虫就是获取互联网公开数据的自动化工具。

这里要强调一下，网络爬虫爬取的是互联网上的**公开数据**，而不是通过特殊技术非法入侵到网站服务器获取的非公开数据。

那么小猿们可能要问，什么是“公开数据”呢？简而言之，就是网站上公开让用户浏览、获取的数据。

虽然数据是公开的，但是当某人或机构（如，搜索引擎）大量收集这些数据并因此获利时，也会让数据生产方——网站很不爽，由此而产生法律纠纷。比如，早些年 Google 因此而惹上官司。

网站们看着搜索引擎因为搜索引擎抓取自己的内容而获利不爽，但也因为搜索引擎带来的流量而高兴不已，于是就出现了网站主动进行搜索引擎优化（SEO, Search Engine Optimization），也就是告诉搜索引擎，我这里的内容好，快来抓取吧！

搜索引擎和网站的博弈，催生了一个君子协议： `robots.txt` 。网站在自己的网站上放上这个文件，告诉爬虫哪些内容可以抓，哪些内容不可以抓；搜索引擎读取网站的robots.txt来知道自己的抓取范围，同时也在访问网站时通过 `User-Agent` 来向网站表明自己的身份（这种表明也是君子协议，技术上很容易假扮他人），比如，Google 的爬虫叫做 Googlebot，百度的爬虫叫做 Baiduspider。这样，二者和平共处，互惠互利。

## 二、大数据时代的网络爬虫

时代在发展，数据变得越来越重要，“大数据”已经成为各行各业讨论的话题，人们对数据的渴望也变成贪婪，数据也就成了“石油”，爬虫也就成了“钻井机”。

为了获取石油，人们使用钻井机；为了获取数据，人们使用爬虫。为了获得数据，人们把互联网钻的是“千疮百孔”。哈哈，这里有些夸张。但人们对数据的获取，已经打破的君子协定，和网站们玩起了猫捉老鼠的游戏，展开了道高一尺魔高一丈的较量。

为什么说是较量呢？因为大量爬虫的行为会给网站带来网络带宽、服务器计算力等方面很大的压力，却几乎不带来任何利益。为了降低这种毫无利益的压力和避免自己的数据被他人集中收集，网站肯定要通过技术手段来限制爬虫；另一方面，爬虫为了获取石油般的数据，就想方设法来突破这种限制。

对于这种较量的理解，还是看活生生的例子来得更透彻。

- 你有没有花几十块钱让某个软件帮你抢火车票？
    - 攻： 抢票爬虫会不断访问 12306 来获得火车票座位数据，并进而购买火车票；
    - 防： 12306 网站出了变态的认证码，人都经常识别错误。
- 各种秒杀让你很受伤！
    - 攻： 研究网站的秒杀机制，提前写好爬虫，秒杀时刻，人快不过机器；
    - 防： 有些秒杀的宣传作用很大就懒得防；有些秒杀机制复杂到你很难写出对应的爬虫；有些秒杀成功被发现作弊也会被取消。

爬虫变得越来越多，越来越肆无忌惮，网站也不得不使用各种技术手段来禁止或限制爬虫。这些手段大致包括：

- 使用账户保护数据，数据仅对登录用户可见；
- 数据多次异步加载；
- 限制 IP 访问频率，甚至封锁IP；
- 输入验证码以获得访问权限；
- 数据在服务器端加密，浏览器端解密；
- ……

而这些手段也是爬虫在技术实现中要解决和突破的问题。

## 三、网络爬虫的自我约束

看完上面“猫捉老鼠”的游戏的描述，小猿们不禁要问，网站和爬虫这种对抗较量会不会引起法律问题？
这是一个很好的问题，也是值得每个爬虫开发者思考的问题。

爬虫作为一种技术本身可能无所谓善恶，但是使用它的人就有善恶之分。如何使用爬虫，爬取的数据如何使用，都可能产生潜在的法律问题。作为技术开发的小猿们，都应该思考这个问题。无论何种目的，网络爬虫都不能突破法律的底线，同时也有遵守一定的准则：

- 遵循 `robots.txt` 协议；
- 避免短时间高并发访问目标网站，避免干扰目标网站的正常运行；
- 不要抓取个人信息，比如手机通讯录等；
- 使用抓来的数据注意隐私保护，合法合规。

守法合规，既是一直自我约束，也是自我保护。

欢迎关注我公众号：AI悦创，有更多更好玩的等你发现！

::: details 公众号：AI悦创【二维码】

![](/gzh.jpg)

:::

::: info AI悦创·编程一对一

AI悦创·推出辅导班啦，包括「Python 语言辅导班、C++ 辅导班、java 辅导班、算法/数据结构辅导班、少儿编程、pygame 游戏开发、Web全栈、Linux」，全部都是一对一教学：一对一辅导 + 一对一答疑 + 布置作业 + 项目实践等。当然，还有线下线上摄影课程、Photoshop、Premiere 一对一教学、QQ、微信在线，随时响应！微信：Jiabcdefh

C++ 信息奥赛题解，长期更新！长期招收一对一中小学信息奥赛集训，莆田、厦门地区有机会线下上门，其他地区线上。微信：Jiabcdefh

方法一：[QQ](http://wpa.qq.com/msgrd?v=3&uin=1432803776&site=qq&menu=yes)

方法二：微信：Jiabcdefh

:::

![](/zsxq.jpg)